{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **\"Generative AI ChatBot\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The purpose of this notebook is to make ChatBots using pretrained models and RAG.\n",
    "\n",
    "#### **Libraries Used:**\n",
    "- gradio\n",
    "- PyPDF2\n",
    "- faiss\n",
    "- numpy\n",
    "- sentence_transformers\n",
    "- google.generativeai\n",
    "- openai\n",
    "- GTTS\n",
    "- temp_file\n",
    "- speech_recognition\n",
    "\n",
    "#### **Work Flow:**\n",
    "- Load model using API key\n",
    "- Read PDF\n",
    "- Make Chunks of the text extracted from PDF\n",
    "- Encode passages using Sentence Transformers\n",
    "- Create FAISS index\n",
    "- Retrieve passages based on input query\n",
    "- Generate answers based on retrieved passages\n",
    "- Mention the source of the response of the bot (from which PDF it took the response and from which page)\n",
    "- Host it on Gradio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+_+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Simple ChatBot using Gemini API**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Gemini API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "os.environ['API_KEY'] = \"AIzaSyDZr1dUJzirLMZu6nPgnKv7XX_AfhVkW10\"\n",
    "\n",
    "# Access your API key as an environment variable.\n",
    "genai.configure(api_key=os.environ['API_KEY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Gemini Model and Generate Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elara wasn't sure how she'd ended up with the backpack. It appeared one rainy afternoon, nestled amongst the discarded newspapers at the back of the bakery where she worked. It was nondescript, faded brown canvas with worn leather straps, but there was something about it that called to her. \n",
      "\n",
      "She took it home, ignoring the whispers of her grandmother, who muttered about \"things best left undisturbed.\" Elara was a curious soul, a collector of stories and experiences, and the backpack felt like the beginning of one.\n",
      "\n",
      "The next day, Elara decided to take it on a hike, the first real adventure since she'd moved to the quiet mountain village. As she walked, the air grew crisp, the scent of pine filling her lungs. She reached into the backpack for her water bottle, but instead, her hand brushed against something smooth and cold. It was a map, a beautifully rendered parchment with swirling ink. It wasn't a map of any place she knew.\n",
      "\n",
      "Curiosity gnawed at her. She followed the map, a thrilling feeling of discovery coursing through her. It led her to a hidden waterfall, a cascade of shimmering water tumbling into a crystal clear pool. She sat by the edge, mesmerized by the sight, and then, as if by magic, a picnic basket materialized at her feet, filled with freshly baked bread, juicy berries, and fragrant cheese. \n",
      "\n",
      "Elara spent the rest of the day exploring the secret trails the map revealed, each place more breathtaking than the last. The backpack provided everything she needed, a change of clothes, a book filled with stories she'd never read before, even a pair of hiking boots that fit perfectly. \n",
      "\n",
      "Days turned into weeks. Elara's life became a kaleidoscope of adventure. She climbed towering peaks, walked through enchanted forests, and even navigated a network of underground caves. The backpack provided her with everything she needed, from rope to climb, to a flashlight that illuminated the darkest corners, to a compass that always pointed her home.\n",
      "\n",
      "But with each adventure, Elara felt a growing unease. The backpack was a bottomless well of wonder, but it was also a constant reminder of how little she knew about the world, about herself. She yearned to share her experiences, to tell someone about the magic she'd found. \n",
      "\n",
      "One day, she decided to return to the bakery, the backpack slung over her shoulder. The baker, her old friend, looked at her with surprise. \"Elara, you lookâ€¦ different,\" he said.\n",
      "\n",
      "She smiled, a new confidence radiating from her. \"I have a story to tell you,\" she said.\n",
      "\n",
      "And so, Elara began to share her adventures, her voice filled with the wonder of discovery. She spoke of waterfalls and hidden caves, of the breathtaking beauty of the world beyond their village. The baker listened, his eyes widening with each tale.\n",
      "\n",
      "As Elara spoke, she realized something profound. The magic wasn't in the backpack. The magic was in the willingness to explore, to embrace the unknown, and to share the stories that shaped her. The backpack was just a catalyst, a tool for a journey that was ultimately hers to make.\n",
      "\n",
      "Elara continued to explore, but now, she carried the backpack with a different understanding. It was no longer a mysterious treasure, but a symbol of the adventure that awaited, both in the world outside and in the depths of her own heart. The real magic, she realized, lay in the journey itself. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Choose a model that's appropriate for your use case.\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "prompt = \"Write a story about a magic backpack.\"\n",
    "\n",
    "response = model.generate_content(prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat with AI continuously and save context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the AI ChatBot! Type 'exit' to quit.\n",
      "You: Hi\n",
      "Bot:  Hi! ðŸ‘‹  How can I help you today? ðŸ˜Š \n",
      "\n",
      "You: How are you\n",
      "Bot:  I'm doing well, thanks for asking! ðŸ˜Š  How can I help you today? \n",
      "\n",
      "You: Name 5 cities in Pakistan\n",
      "Bot:  Here are 5 cities in Pakistan:\n",
      "\n",
      "1. **Karachi:** The largest city in Pakistan and its financial hub.\n",
      "2. **Lahore:** The second-largest city and the cultural heart of Pakistan.\n",
      "3. **Islamabad:** The capital city of Pakistan.\n",
      "4. **Faisalabad:** A major industrial center in Pakistan.\n",
      "5. **Rawalpindi:** A garrison city and a major administrative center. \n",
      "\n",
      "You: Great! Name some of the famous dishes of these cities\n",
      "Bot:  Here are some famous dishes from the cities you listed:\n",
      "\n",
      "**Karachi:**\n",
      "\n",
      "* **Biryani:**  A flavorful rice dish with meat, often chicken or goat. \n",
      "* **Nihari:** A rich and aromatic stew made with slow-cooked meat, usually beef.\n",
      "* **Fish Tikka:**  Marinated fish grilled to perfection.\n",
      "* **Sindhi Biryani:** A unique variant of biryani specific to Sindh, often with a sweeter flavor.\n",
      "\n",
      "**Lahore:**\n",
      "\n",
      "* **Lahore Karahi:** A spicy and flavorful meat curry cooked in a large wok.\n",
      "* **Samosa Chaat:** Crispy samosas filled with spiced potatoes and peas, served with chutneys and yogurt.\n",
      "* **Halwa Puri:** A breakfast dish of fried bread served with chickpeas, yogurt, and sweet halwa.\n",
      "* **Paye:** A rich and flavorful dish made with cow or goat trotters.\n",
      "\n",
      "**Islamabad:**\n",
      "\n",
      "* **Peshawari Chapli Kebab:** Spicy ground meat patties grilled to perfection.\n",
      "* **Achar Gosht:** A flavorful meat dish cooked with pickled vegetables.\n",
      "* **Daal Chawal:** A simple and comforting dish of lentils and rice.\n",
      "* **Sajji:** A roasted chicken or lamb dish marinated in yogurt and spices.\n",
      "\n",
      "**Faisalabad:**\n",
      "\n",
      "* **Chicken Tikka Masala:** A popular dish with chicken marinated in yogurt and spices, cooked in a creamy tomato sauce.\n",
      "* **Fish Karahi:**  A flavorful dish with fish cooked in a karahi with spices and onions.\n",
      "* **Haleem:** A rich and hearty stew made with meat, lentils, and wheat, popular during the holy month of Ramadan.\n",
      "* **Lassi:** A sweet and refreshing yogurt drink.\n",
      "\n",
      "**Rawalpindi:**\n",
      "\n",
      "* **Nihari:** (As mentioned earlier, this dish is also popular in Karachi)\n",
      "* **Qeema:** A spiced minced meat dish.\n",
      "* **Sajji:** (As mentioned earlier, this dish is also popular in Islamabad)\n",
      "* **Paratha:**  A flaky and buttery flatbread. \n",
      "\n",
      "Remember, this is just a sampling of the many delicious dishes you can find in Pakistan. Each city has its own unique culinary traditions and variations on these dishes. \n",
      "\n",
      "You: Ok, Thanks\n",
      "Bot:  The user's response \"Ok, Thanks\" indicates they are satisfied with the information provided. There's no further question or request, so there's nothing else to answer. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Answer the question below:\n",
    "\n",
    "Here is the conversation history: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "def handle_conversation():\n",
    "    context = \"\"\n",
    "    print(\"Welcome to the AI ChatBot! Type 'exit' to quit.\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            break\n",
    "        prompt = template.format(context=context, question=user_input)\n",
    "        \n",
    "        # Print the user's input before generating the response\n",
    "        print(f\"You: {user_input}\")\n",
    "        \n",
    "        # Call the model to generate content\n",
    "        response = model.generate_content(prompt)\n",
    "        \n",
    "        # Extract the text from the response\n",
    "        try:\n",
    "            if hasattr(response, 'candidates') and response.candidates:\n",
    "                bot_response = response.candidates[0].content.parts[0].text\n",
    "                print(\"Bot: \", bot_response)\n",
    "            else:\n",
    "                print(\"Bot: Sorry, I couldn't generate a response.\")\n",
    "        except Exception as e:\n",
    "            print(\"Error accessing response content:\", e)\n",
    "\n",
    "        # Save and update the context with the latest interaction\n",
    "        context += f\"\\nUser: {user_input}\\nAI: {bot_response}\"\n",
    "\n",
    "handle_conversation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Host custom bot on **Gradio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Define the prompt template\n",
    "template = \"\"\"\n",
    "Answer the question below:\n",
    "\n",
    "Here is the conversation history: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Function to handle user input and generate responses\n",
    "def CustomChatGPT(user_input, context):\n",
    "    prompt = template.format(context=context, question=user_input)\n",
    "    \n",
    "    # Call the model to generate content\n",
    "    response = model.generate_content(prompt)  # Adjust this line based on the correct method to call the model\n",
    "    \n",
    "    # Extract the text from the response\n",
    "    try:\n",
    "        if hasattr(response, 'candidates') and response.candidates:\n",
    "            bot_response = response.candidates[0].content.parts[0].text\n",
    "        else:\n",
    "            bot_response = \"Sorry, I couldn't generate a response.\"\n",
    "    except Exception as e:\n",
    "        bot_response = f\"Error accessing response content: {e}\"\n",
    "\n",
    "    # Update the context with the latest interaction\n",
    "    new_context = f\"{context}\\nUser: {user_input}\\nAI: {bot_response}\"\n",
    "    \n",
    "    return bot_response, new_context  # Return both the bot response and updated context\n",
    "\n",
    "# Create Gradio interface\n",
    "demo = gr.Interface(\n",
    "    fn=CustomChatGPT,\n",
    "    inputs=[\"text\", \"state\"],  # Input for user question and state for context\n",
    "    outputs=[\"text\", \"state\"],  # Output for bot response and updated context\n",
    "    title=\"Generative AI ChatBot\",\n",
    "    description=\"Hey! I'm your personal Generative AI ChatBot. Ask me anything!\",\n",
    ")\n",
    "\n",
    "# Launch the Gradio app\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ChatBot for answering queries from a given PDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "import google.generativeai as genai\n",
    "\n",
    "os.environ['API_KEY'] = \"AIzaSyDZr1dUJzirLMZu6nPgnKv7XX_AfhVkW10\"\n",
    "\n",
    "# Access your API key as an environment variable.\n",
    "genai.configure(api_key=os.environ['API_KEY'])\n",
    "\n",
    "# Initialize the generative model\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and extract text from PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "def read_pdf(pdf_file):\n",
    "    pdf_text = ''\n",
    "    with open(pdf_file.name, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        for page in pdf_reader.pages:\n",
    "            pdf_text += page.extract_text() + \"\\n\" \n",
    "    return pdf_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create prompt based on query and extracted text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt template\n",
    "def create_prompt(pdf_text, context, question):\n",
    "    return f\"\"\"\n",
    "    Here is the relevant context from the PDF:\n",
    "    {pdf_text}\n",
    "\n",
    "    Answer the question below:\n",
    "\n",
    "    Here is the conversation history: {context}\n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate response based on query and extracted text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CustomChatGPT(user_input, context, pdf_file):\n",
    "    # Read the PDF text\n",
    "    pdf_text = read_pdf(pdf_file)  # Use the uploaded file's name\n",
    "    prompt = create_prompt(pdf_text, context, user_input)\n",
    "    \n",
    "    # Call the model to generate content\n",
    "    response = model.generate_content(prompt)\n",
    "    \n",
    "    # Extract the text from the response\n",
    "    try:\n",
    "        if hasattr(response, 'candidates') and response.candidates:\n",
    "            bot_response = response.candidates[0].content.parts[0].text\n",
    "        else:\n",
    "            bot_response = \"Sorry, I couldn't generate a response.\"\n",
    "    except Exception as e:\n",
    "        bot_response = f\"Error accessing response content: {e}\"\n",
    "\n",
    "    # Update the context with the latest interaction\n",
    "    new_context = f\"{context}\\nUser: {user_input}\\nAI: {bot_response}\"\n",
    "    \n",
    "    return bot_response, new_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Host it on Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Gradio interface\n",
    "demo = gr.Interface(\n",
    "    fn=CustomChatGPT,\n",
    "    inputs=[gr.Textbox(label=\"Your Question\"), gr.State(), gr.File(label=\"Upload PDF\")],  # Updated input types\n",
    "    outputs=[gr.Textbox(label=\"Response\"), gr.State()],  # Updated output types\n",
    "    title=\"Generative AI ChatBot\",\n",
    "    description=\"Hey! I'm your personal Generative AI ChatBot. Ask me anything based on the PDF you upload!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7923\n",
      "Running on public URL: https://bcc0145e5198cd96a2.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://bcc0145e5198cd96a2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The method used above to read from PDF and generate answers based on it is not correct. Here are some reasons why its not an effective solution:\n",
    "\n",
    "- PDFs are large files that can be difficult to process.\n",
    "- The model is still using GPT knowledge to generate content.\n",
    "- The model must only answer the query from text provided in the PDF.\n",
    "\n",
    "### To solve this issue, we are using the RAG method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Using RAG**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The workflow for applying RAG is as follows:\n",
    "\n",
    "1. Read PDF\n",
    "2. Make Chunks of the text extracted from PDF (this is done to reduce the size of the model input tokens and it will be able to read large PDFs)\n",
    "3. Encode passages using Sentence Transformers (this is done because we have to convert text to vectors)\n",
    "4. Create FAISS index (this is done to search the passages in the index)\n",
    "5. Retrieve passages based on input query\n",
    "6. Generate answers based on retrieved passages\n",
    "7. Mention the source of the response of the bot (from which PDF it took the response and from which page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import google.generativeai as genai\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['API_KEY'] = \"AIzaSyDZr1dUJzirLMZu6nPgnKv7XX_AfhVkW10\"  # Replace with your actual API key\n",
    "genai.configure(api_key=os.environ['API_KEY'])\n",
    "\n",
    "# Choose a model\n",
    "gen_model = genai.GenerativeModel('gemini-1.5-flash')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize variables to store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = []\n",
    "pdf_data = []  # To store passages and their metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read Multiple PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdfs(pdf_files):\n",
    "    all_texts = []\n",
    "    for pdf_file in pdf_files:\n",
    "        text = \"\"\n",
    "        with open(pdf_file.name, 'rb') as file:\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "            for page_num, page in enumerate(pdf_reader.pages):\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "        pdf_name = os.path.basename(pdf_file.name)\n",
    "        all_texts.append((text, pdf_name))\n",
    "    return all_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Make Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_chunks(text, pdf_name, chunk_size=500, chunk_overlap=50):\n",
    "    chunks = []\n",
    "    page_numbers = []\n",
    "    start = 0\n",
    "    page = 1  # Start with page 1\n",
    "    while start < len(text):\n",
    "        chunk = text[start:start + chunk_size]\n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "            page_numbers.append((pdf_name, page))\n",
    "        start += chunk_size - chunk_overlap\n",
    "        if start % chunk_size == 0:  # Move to next page roughly after chunk size\n",
    "            page += 1\n",
    "    return chunks, page_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Encode passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def encode_passages(passages):\n",
    "    embeddings = sentence_model.encode(passages, convert_to_tensor=True)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create FAISS index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(embeddings):\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    index.add(embeddings.cpu().numpy())\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Retrieve passages based on query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_passages(index, passages, page_numbers, query, k=5):\n",
    "    query_embedding = sentence_model.encode(query, convert_to_tensor=True)\n",
    "    query_embedding = np.expand_dims(query_embedding, axis=0)\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "    relevant_passages = []\n",
    "    relevant_page_numbers = []\n",
    "\n",
    "    for i in range(k):\n",
    "        if indices[0][i] < len(passages) and distances[0][i] < 1.3:  # Threshold for relevance\n",
    "            relevant_passages.append(passages[indices[0][i]])\n",
    "            relevant_page_numbers.append(page_numbers[indices[0][i]])\n",
    "\n",
    "    return list(zip(relevant_passages, relevant_page_numbers)), distances[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Generate answer based on retrieved passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(gen_model, prompt, retrieved_passages):\n",
    "    response = \"\"\n",
    "    sources_info = {}\n",
    "\n",
    "    # Collect passages by source\n",
    "    for passage, (pdf, page) in retrieved_passages:\n",
    "        if (pdf, page) not in sources_info:\n",
    "            sources_info[(pdf, page)] = []\n",
    "        sources_info[(pdf, page)].append(passage)\n",
    "\n",
    "    # Construct the response\n",
    "    for (pdf, page), passages in sources_info.items():\n",
    "        # Join all passages from the same source and page\n",
    "        response += \"\\n\".join(passages) + f\" [Source: {pdf}, Page: {page}]\\n\\n\"\n",
    "\n",
    "    # Generate the final response text\n",
    "    response_text = gen_model.generate_content(prompt + \"\\n\\n\" + response)\n",
    "\n",
    "    # Prepare sources list\n",
    "    unique_sources = set(sources_info.keys())\n",
    "    sources_list = \"\\n\".join([f\"[Source: {pdf}, Page: {page}]\" for pdf, page in unique_sources])\n",
    "\n",
    "    return response_text.text + \"\\n\\nSources:\\n\" + sources_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Define chatbot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(prompt, state, pdf_files):\n",
    "    global indexes, pdf_data  # Declare global variables\n",
    "    pdf_data = []  # Reset for new input\n",
    "    indexes = []\n",
    "\n",
    "    # Read and process the PDFs\n",
    "    all_texts = read_pdfs(pdf_files)\n",
    "    for text, pdf_name in all_texts:\n",
    "        passages, page_numbers = make_chunks(text, pdf_name)\n",
    "        embeddings = encode_passages(passages)\n",
    "        index = create_index(embeddings)\n",
    "        indexes.append((index, passages, page_numbers))\n",
    "\n",
    "    # Retrieve relevant passages from all PDFs\n",
    "    retrieved_passages = []\n",
    "    for index, passages, page_numbers in indexes:\n",
    "        passages_batch, distances = retrieve_passages(index, passages, page_numbers, prompt)\n",
    "\n",
    "        # Debugging output\n",
    "        print(f\"Distances: {distances}\")\n",
    "        \n",
    "        # Check if any retrieved passages have a low distance (indicating relevance)\n",
    "        if len(distances) > 0 and np.any(distances < 1.3):  # Adjust threshold as needed\n",
    "            retrieved_passages.extend(passages_batch)\n",
    "\n",
    "    # Generate response based on the retrieved passages\n",
    "    if not retrieved_passages:\n",
    "        response = \"I don't have this information. For more information, contact +123456789.\" # If info asked is out of PDF\n",
    "    else:\n",
    "        response = generate_answer(gen_model, prompt, retrieved_passages)\n",
    "\n",
    "    return response, state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7924\n",
      "Running on public URL: https://cfeae7ac24689cd6ea.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://cfeae7ac24689cd6ea.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Gradio interface\n",
    "demo = gr.Interface(\n",
    "    fn=chatbot,\n",
    "    inputs=[\"text\", \"state\", gr.File(label=\"Upload PDFs\", file_count=\"multiple\")],\n",
    "    outputs=[\"text\", \"state\"],\n",
    "    title=\"Generative AI Chatbot with RAG\",\n",
    "    description=\"Ask me anything based on the uploaded PDFs!\",\n",
    ")\n",
    "\n",
    "# Launch the Gradio app\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Adding additional features (Input queries in voice and get voice responses)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PMLS\\anaconda3\\envs\\traning_env\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\PMLS\\anaconda3\\envs\\traning_env\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import google.generativeai as genai\n",
    "import gradio as gr\n",
    "from gtts import gTTS\n",
    "import tempfile\n",
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['API_KEY'] = \"AIzaSyDZr1dUJzirLMZu6nPgnKv7XX_AfhVkW10\"  # Replace with your actual API key\n",
    "genai.configure(api_key=os.environ['API_KEY'])\n",
    "\n",
    "# Choose a model\n",
    "gen_model = genai.GenerativeModel('gemini-1.5-flash')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = []\n",
    "pdf_data = []  # To store passages and their metadata\n",
    "\n",
    "def read_pdfs(pdf_files):\n",
    "    all_texts = []\n",
    "    for pdf_file in pdf_files:\n",
    "        text = \"\"\n",
    "        with open(pdf_file.name, 'rb') as file:\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "            for page_num, page in enumerate(pdf_reader.pages):\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "        pdf_name = os.path.basename(pdf_file.name)\n",
    "        all_texts.append((text, pdf_name))\n",
    "    return all_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Chunks of Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_chunks(text, pdf_name, chunk_size=500, chunk_overlap=50):\n",
    "    chunks = []\n",
    "    page_numbers = []\n",
    "    start = 0\n",
    "    page = 1  # Start with page 1\n",
    "    while start < len(text):\n",
    "        chunk = text[start:start + chunk_size]\n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "            page_numbers.append((pdf_name, page))\n",
    "        start += chunk_size - chunk_overlap\n",
    "        if start % chunk_size == 0:  # Move to next page roughly after chunk size\n",
    "            page += 1\n",
    "    return chunks, page_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "def encode_passages(passages):\n",
    "    embeddings = sentence_model.encode(passages, convert_to_tensor=True)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create FAISS index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(embeddings):\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    index.add(embeddings.cpu().numpy())\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve passages based on input query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_passages(index, passages, page_numbers, query, k=5):\n",
    "    query_embedding = sentence_model.encode(query, convert_to_tensor=True)\n",
    "    query_embedding = np.expand_dims(query_embedding, axis=0)\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "    relevant_passages = []\n",
    "    relevant_page_numbers = []\n",
    "\n",
    "    for i in range(k):\n",
    "        if indices[0][i] < len(passages) and distances[0][i] < 1.3:  # Threshold for relevance\n",
    "            relevant_passages.append(passages[indices[0][i]])\n",
    "            relevant_page_numbers.append(page_numbers[indices[0][i]])\n",
    "\n",
    "    return list(zip(relevant_passages, relevant_page_numbers)), distances[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate answer based on retrieved passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(gen_model, prompt, retrieved_passages):\n",
    "    response = \"\"\n",
    "    sources_info = {}\n",
    "\n",
    "    # Collect passages by source\n",
    "    for passage, (pdf, page) in retrieved_passages:\n",
    "        if (pdf, page) not in sources_info:\n",
    "            sources_info[(pdf, page)] = []\n",
    "        sources_info[(pdf, page)].append(passage)\n",
    "\n",
    "    # Construct the response\n",
    "    for (pdf, page), passages in sources_info.items():\n",
    "        response += \"\\n\".join(passages) + f\" [Source: {pdf}, Page: {page}]\\n\\n\"\n",
    "\n",
    "    # Generate the final response text\n",
    "    response_text = gen_model.generate_content(prompt + \"\\n\\n\" + response)\n",
    "\n",
    "    # Prepare sources list\n",
    "    unique_sources = set(sources_info.keys())\n",
    "    sources_list = \"\\n\".join([f\"[Source: {pdf}, Page: {page}]\" for pdf, page in unique_sources])\n",
    "\n",
    "    return response_text.text + \"\\n\\nSources:\\n\" + sources_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to convert audio to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_text(audio_file):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio = recognizer.record(source)\n",
    "        try:\n",
    "            return recognizer.recognize_google(audio)\n",
    "        except sr.UnknownValueError:\n",
    "            return \"Could not understand audio.\"\n",
    "        except sr.RequestError:\n",
    "            return \"Could not request results from Google Speech Recognition service.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatBot function with RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(prompt, pdf_files):\n",
    "    global indexes, pdf_data  # Declare global variables\n",
    "    pdf_data = []  # Reset for new input\n",
    "    indexes = []\n",
    "\n",
    "    # Read and process the PDFs\n",
    "    all_texts = read_pdfs(pdf_files)\n",
    "    for text, pdf_name in all_texts:\n",
    "        passages, page_numbers = make_chunks(text, pdf_name)\n",
    "        embeddings = encode_passages(passages)\n",
    "        index = create_index(embeddings)\n",
    "        indexes.append((index, passages, page_numbers))\n",
    "\n",
    "    # Retrieve relevant passages from all PDFs\n",
    "    retrieved_passages = []\n",
    "    for index, passages, page_numbers in indexes:\n",
    "        passages_batch, distances = retrieve_passages(index, passages, page_numbers, prompt)\n",
    "\n",
    "        # Debugging output\n",
    "        print(f\"Distances: {distances}\")\n",
    "        \n",
    "        # Check if any retrieved passages have a low distance (indicating relevance)\n",
    "        if len(distances) > 0 and np.any(distances < 1.3):  # Adjust threshold as needed\n",
    "            retrieved_passages.extend(passages_batch)\n",
    "\n",
    "    # Generate response based on the retrieved passages\n",
    "    if not retrieved_passages:\n",
    "        response = \"I don't have this information. For more information, contact +123456789.\"\n",
    "    else:\n",
    "        response = generate_answer(gen_model, prompt, retrieved_passages)\n",
    "\n",
    "    # Convert response to speech\n",
    "    tts = gTTS(response, lang='en')\n",
    "    audio_file = tempfile.NamedTemporaryFile(delete=True)\n",
    "    tts.save(audio_file.name + \".mp3\")\n",
    "    audio_file.seek(0)  # Reset file pointer to the beginning\n",
    "\n",
    "    return response, audio_file.name + \".mp3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom CSS for Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "css = \"\"\"\n",
    ".gradio-container {\n",
    "    background-color: #A9957B;  /* Light blue background */\n",
    "}\n",
    "input[type=\"file\"], input[type=\"text\"], textarea, audio, button {\n",
    "    width: 100%;  /* Make inputs and buttons larger */\n",
    "    font-size: 1.2em;  /* Increase font size of inputs and buttons */\n",
    "    padding: 2px;  /* Add padding for better spacing */\n",
    "    margin: 10px 0;  /* Add margin for spacing between elements */\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Final Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://d22aa7898dd80935bb.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://d22aa7898dd80935bb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: [1.6039616 1.753724  1.7572083 1.7860916 1.7874644]\n"
     ]
    }
   ],
   "source": [
    "# Define the clear function\n",
    "def clear_inputs():\n",
    "    return None, \"\", \"\", None\n",
    "\n",
    "# Create Gradio interface\n",
    "with gr.Blocks(css=css) as demo:\n",
    "    gr.Markdown(\"<h1 style='height: 100px; color: white; font-size: 70px; text-align: center;'>Generative AI Chatbot</h1>\")\n",
    "    gr.Markdown(\"<h4 style='height: 75px; color: white; font-size: 30px; font-weight: italic; text-align: center;'>Ask me questions based on the uploaded PDFs!</h4>\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        pdf_files = gr.File(label=\"Upload PDFs\", file_count=\"multiple\")\n",
    "        voice_input = gr.Audio(label=\"Speak your query\", type=\"filepath\")  # Real-time voice input\n",
    "        text_input = gr.Textbox(label=\"Type your query\")  # Text input\n",
    "    submit_btn = gr.Button(\"Submit\")\n",
    "\n",
    "    text_output = gr.Textbox(label=\"Bot Response\")\n",
    "    chatbot_output = gr.Audio(label=\"Bot Response Audio\")\n",
    "    clear_btn = gr.Button(\"Clear\")\n",
    "    \n",
    "    def handle_input(voice_file, text_query, pdf_files):\n",
    "        # Determine which input to use\n",
    "        if voice_file:\n",
    "            query = audio_to_text(voice_file)\n",
    "        else:\n",
    "            query = text_query\n",
    "        \n",
    "        return chatbot(query, pdf_files)\n",
    "\n",
    "    submit_btn.click(handle_input, \n",
    "                      inputs=[voice_input, text_input, pdf_files], \n",
    "                      outputs=[text_output, chatbot_output])\n",
    "    \n",
    "    clear_btn.click(clear_inputs, \n",
    "                    inputs=[], \n",
    "                    outputs=[voice_input, text_input, text_output, chatbot_output])\n",
    "\n",
    "# Launch the Gradio app\n",
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traning_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
